---
layout: post
title: "《设计数据密集型应用》 第一部分 数据系统的基石"
date:   2025-1-20
tags: [设计数据密集型应用]
comments: true
author: huanghuoguoguo
---

# 本书开始阅读之前携带的疑问

内存中的map可以被视为一种最简单的数据库形式。它使用起来极为便捷：存储键值对（key-value），并能根据键快速检索对应的值，性能表现十分出色。然而，内存作为一种易失性存储设备，一旦断电，其中的数据便会瞬间消失。因此，为了确保数据在断电重启后依然可以被访问，我们需要为map添加持久化功能。最直接的实现方式是序列化——将map对象序列化到磁盘上，并在启动时将其反序列化为map对象。

接下来，我们面临几个关键问题：

- **应该在何时进行序列化？**如果每次操作后都立即序列化，虽然能保证数据的即时性，但序列化本身是一个耗时操作，会导致无法忍受的延迟。
- 是对整个map对象进行序列化，还是仅序列化其中的部分内容？毕竟，那些未被修改的部分是否真的有必要重复序列化呢？
- **这个map是否线程安全？（是否要引入事务？原子性操作？）**在多线程环境下，数据是否会因并发操作而出现覆盖问题？如果执行失败了呢？（undo log）
- **在序列化过程中，是否需要阻塞所有操作？**如果仅在程序开始和结束时进行序列化，那么在中间发生断电怎么办？（double write pool）（disk buffer pool）
- 数据量逐渐大了之后，是不是考虑所有数据都存储在单机的内存或者磁盘中，是不是可以尝试**分片**？将数据分散存储后，怎么**搜索和整合**呢？分片情况下的索引该怎么做呢？
- 是不是要像raid那样做数据冗余呢？增强安全性？（**复制**）

带着这些问题，我们开始探索这本书。凭借我目前的知识储备，我已经对其中部分问题有了一些初步的见解。

以**InnoDB**为例，它采用了以下机制来解决类似问题：

- **Disk Buffer Pool**：通过池化操作，将页面暂存于内存中。利用局部性原理，它可以显著提升CPU、内存和磁盘之间的交互性能，减少不必要的数据交换。
- 然而，仅靠Disk Buffer Pool是不够的。因为如果发生宕机，Pool中的脏页可能来不及写入磁盘，从而导致数据丢失。因此，InnoDB引入了重做日志（redo log）来记录这些操作，以便在系统重启时能够重放这些操作，确保数据的完整性。
- 那么，为什么选择使用**redo log**呢？难道它不需要写入磁盘吗？当然需要，但redo log采用环形结构，并且是顺序写入，这使得其写入性能非常高。相比之下，Disk Buffer Pool的换入换出操作是随机写入的，性能较低。InnoDB通过这种折中方案，既保证了高性能，又确保了数据的安全性。
- 

从一个简单的内存 `map` 开始，我们逐步添加了持久化、日志结构、索引、事务支持、并发控制、分布式扩展以及性能优化等功能。每一步都是为了满足新的需求，解决新的问题。通过这个过程，我们可以清晰地看到一个简单的数据结构如何逐步演化为一个功能完备的数据库系统。

当我们将视野拓展到分布式系统时，数据不再集中于同一块主板，这又会带来哪些新的挑战呢？关键词包括：分片、复制和事务。 在阅读这本书的过程中，我结合了自己对MySQL、Redis、RocketMQ、Kafka、RabbitMQ、OceanBase、XXL-Job、Elasticsearch和MongoDB高可用方案的了解，不断进行联想和对比，以加深对这些概念的理解。



# 第一部分：数据系统的基石

第一部分讨论设计数据密集型应用所依赖的基本思想。讨论如何达到第一章的目标，如何思考这些概念，以及如何实现他们。然后从这些思想出发，从上到下的思考问题，比较不同的数据模型和查询语言，讨论他们的适用场景。然后讨论存储引擎，然后再讨论序列化，更底层的数据流表示。

## 第一章：可靠性、可扩展性、可维护性

数据存储可以被当成消息队列使用（redis），消息队列则带有类似数据库的持久化保证（kafka）

以推特发推文的例子举例，以业务场景来说明，混合的架构可能更合适。但是都遵循一个关键点--将资源合理利用。

应对负载的方法

数据库更倾向于纵向扩展（单点）

为了实现标题的这几个点，可能需要考虑哪些问题。

## 第二章：数据模型与查询语言

每个层都通过提供一个明确的数据模型来隐藏更底层次中的复杂性。这些抽象允许不同的人群有效的协作。

学习时考虑能做什么，不能做什么即可。

关系数据库和nosql，

不同的应用程序有不同的需求，不同的技术也在某些方面呈现更好的性能。

JSON表示具有更好的局部性。

介绍了很多搜索模型和语言，不过都不太认识，全部补起来的话时间太长了，有个概念就可以了。

文档型数据库的应用场景：数据通常是自我包含的，而且文档之间的关系非常稀少。

图形数据库用于相反的场景：任意事物都可能与任何事物相关联。

有非常多的数据结构，或者组件，或者开源项目等，在高性能上，都采取了粗查询再细查询甚至细查询用顺序扫描的方式，比如mysql在业内扫描可能会直接顺序扫描，redis小数据量用quicklist顺序扫描等，他们是受什么指导思想影响的呢？是因为小数据范围内顺序扫描实测比用一些大范围的数据结构还要快是吗？

在高性能数据库系统中，粗查询再细查询以及顺序扫描的策略被广泛应用，这背后的核心指导思想是“局部性原理”和“性能与复杂度的权衡”。以下是这些策略的指导思想和应用场景的详细解释：

------

### 1. 局部性原理与顺序扫描的优势

局部性原理指出，数据访问通常集中在一小部分数据上，尤其是在时间局部性和空间局部性上。基于这一原理，顺序扫描在某些场景下比复杂的数据结构（如索引）更高效，原因包括：

- 顺序读取的高效性：顺序扫描利用了磁盘的顺序读取特性，减少了磁盘寻道时间和旋转延迟，从而提高了读取效率。
- 缓存友好性：顺序扫描的数据通常更容易被缓存命中，减少了对磁盘的访问次数。
- 小数据量的优化：对于小数据集，顺序扫描的开销较小，且不需要复杂的索引维护，因此在性能上可能优于索引扫描。

------

### 2. 粗查询再细查询的策略

这种策略的核心思想是“先快速定位范围，再精确筛选”，适用于大规模数据集的查询优化：

- 粗查询：通过简单的条件快速定位数据的大致范围，减少需要处理的数据量。
- 细查询：在粗查询的结果中进行精确筛选，进一步优化查询性能。

例如，在MySQL中，当索引不能完全覆盖查询条件时，可能会先通过索引快速定位到部分数据，再通过顺序扫描完成最终的查询。

------

### 3. 为什么顺序扫描在某些场景下比复杂数据结构更快？

- 小数据量场景：对于小数据集，顺序扫描的简单性使其性能优于复杂的索引结构。
- 避免随机IO：顺序扫描减少了随机IO操作，尤其是在数据量较大时，顺序读取的性能优势更加明显。
- 减少索引维护开销：索引虽然可以加速查询，但维护索引本身需要额外的存储空间和计算资源。对于某些场景，顺序扫描可以避免这些开销。

------

### 4. 实际应用中的例子

- MySQL：在某些情况下，MySQL会选择顺序扫描而不是索引扫描，尤其是在数据量较大且索引不能覆盖查询条件时。
- Redis：对于小数据量的列表操作，Redis使用`quicklist`结构，通过顺序扫描完成查询。这种策略在小数据量时效率很高，且避免了复杂数据结构的开销。

------

这种策略的核心指导思想是**“在小数据范围内，顺序扫描的简单性和高效性优于复杂数据结构”**。通过利用局部性原理和顺序读取的高效性，这些系统在某些场景下能够实现比复杂索引结构更高的性能。这种策略尤其适用于小数据量查询、大规模数据的初步筛选以及需要减少索引维护开销的场景。

## 第三章：存储与检索

一个数据库应当做到两件基础的事情：当你把数据交给数据库时，它应当存起来；当你需要这部分数据时，它应当还给你。为了实现这一目标，数据库的存储引擎设计至关重要。研究两类存储引擎：日志结构的存储引擎和面向页面的存储引擎。

#### 日志结构的存储引擎

日志是一个仅追加的文件，可能是二进制的，也可能是文本的。它的特点是性能很高，因为是顺序追加的（顺序写）。这种结构的典型代表是**LSM树（Log-Structured Merge Tree）和SSTables（Sorted String Tables）**。

**SSTables** 是一种分段存储的结构，每个段内保持大致有序。在内存中维护当前段，当段的大小达到一定程度后，将其写入磁盘并进行压缩。SSTables的索引主要用于加速查询，每次查询时，先查内存，再查磁盘上的段，一个一个向前查询。为了避免查询不存在的键，可以使用**布隆过滤器（Bloom Filter）**。

**LSM树** 是一种将写入操作优化到极致的数据结构。它通过将数据先写入内存中的一个有序结构（如跳表），然后定期将这些数据批量写入磁盘上的SSTables。这种方式在写入时非常高效，但在读取时可能需要合并多个段的数据，因此需要在写入和读取之间进行权衡。

#### 面向页面的存储引擎

与日志结构不同，面向页面的存储引擎（如**B树**）将数据存储在固定大小的页面中。B树是一种平衡树结构，适用于范围查询和排序操作。它通过保持数据的有序性来加速范围查询，但写入时可能需要频繁调整树结构，从而导致写入性能下降。

为了优化B树的性能，可以采用以下策略：

1. **批量操作**：减少磁盘I/O次数。
2. **缓存机制**：将常用节点保存在内存中。
3. **预读和延迟写**：减少读写次数。
4. **节点大小设计**：使节点大小与磁盘块大小一致。

#### 性能优化与应用场景

- **LSM树的优点**：写入性能高，适合高吞吐量的写入场景。
- **LSM树的缺点**：读取时可能需要合并多个段，性能不如B树。
- **B树的优点**：读取性能高，适合范围查询。
- **B树的缺点**：写入时需要调整树结构，性能可能受限。

在实际应用中，选择哪种存储引擎取决于具体需求。例如，对于写入密集型的应用（如日志系统），LSM树可能是更好的选择；而对于读取密集型的应用（如关系型数据库），B树可能更适合。

#### 其他索引结构

除了B树和LSM树，还有一些其他索引结构：

1. **哈希索引**：适用于快速点查询，但不支持范围查询。
2. **多列索引**：允许在多个列上建立索引，提高查询效率。
3. **全文搜索和模糊索引**：用于支持复杂的文本搜索，如MySQL的全文索引。
4. **内存存储优化**：将数据存储在内存中，提高访问速度。




## 第四章：编码与演化



encode，decode，讲了一下一些例子，但是不是很明白。还讲了一些向前兼容和向后兼容。

Avro模式，读者模式，作者模式

这一章主要探讨了数据系统的编码与演化问题。具体来说，它讨论了以下几个方面：

1. **应用程序的变化**：应用程序会随着时间推移而变化，这些变化通常伴随着数据格式或模式的更改。
2. **数据格式和模式的变化**：当数据格式或模式发生变化时，需要对应用程序代码进行相应的更改，但在大型应用程序中，代码变更通常不会立即完成，新旧版本的代码和数据格式可能会同时共处。
3. **双向兼容性**：为了使系统能够继续顺利运行，需要保持双向兼容性，即新代码可以读旧数据，旧代码可以读新数据。
4. **编码数据的格式**：介绍了几种常见的编码数据格式，包括 JSON、XML、Protocol Buffers、Thrift 和 Avro，并特别关注这些格式如何应对模式变化，以及它们如何支持新旧代码和数据共存的系统。
5. **数据存储和通信**：讨论了如何使用这些格式进行数据存储和通信，包括在 Web 服务中的具象状态传输（REST）和远程过程调用（RPC），以及消息传递系统（如 Actor 和消息队列）。



### 指导意义

1. **设计灵活的数据系统**：这一章提供了设计能够灵活适应变化的数据系统的指导，帮助读者在构建数据系统时考虑到未来的变化。
2. **选择合适的编码格式**：通过对比不同编码格式的特点和优缺点，读者可以更好地选择适合其应用程序的编码格式。
3. **实现双向兼容性**：这一章提供了实现双向兼容性的具体策略和方法，帮助读者在系统演进过程中保持数据的一致性和可用性。
4. **应对实际问题**：通过实际案例和应用场景的讨论，读者可以了解到如何在实际工作中应用这些理论和策略，解决数据编码和演化中的具体问题。

总之，这一章为读者提供了全面的指导，帮助他们理解和应对数据系统的编码与演化问题，确保数据系统在不断变化的环境中能够稳定运行。

### 第四章：编码与演化

#### 1. 应用程序的变化与数据格式/模式的更改

- **背景**：应用程序会因新产品推出、需求深入理解或商业环境变化而不断演变，通常伴随着功能的增删改。
- **影响**：修改应用程序功能往往需要更改其存储的数据，如新增字段或记录类型，或以新方式展示现有数据。

#### 2. 代码变更与数据格式共存

- **现状**：在大型应用程序中，代码变更不会立即完成，导致新旧版本代码及数据格式可能同时存在。
- **需求**：系统需保持双向兼容性，即新代码能读旧数据，旧代码能读新数据，以确保顺利运行。

#### 3. 双向兼容性

- **向后兼容**：新代码可读旧数据，较易实现，新代码作者了解旧数据格式，可显式处理（如保留旧代码读取旧数据）。
- **向前兼容**：旧版程序需忽略新版数据格式新增部分，实现较棘手。

#### 4. 编码数据的格式及应对模式变化

- **常见格式**：介绍了 JSON、XML、Protocol Buffers、Thrift 和 Avro 等编码数据格式。
- **模式变化应对**：特别关注这些格式如何应对模式变化，支持新旧代码数据共存系统，如 Avro 的作者模式和读者模式，通过兼容性规则（如添加或删除带默认值字段、字段名称别名、联合类型等）保持数据兼容。

#### 5. 数据存储和通信的应用

- **Web 服务**：讨论了在 Web 服务中使用这些格式进行数据存储和通信，如具象状态传输（REST）和远程过程调用（RPC）。
- **消息传递系统**：探讨了在消息传递系统（如 Actor 和消息队列）中应用这些格式，以实现高效的数据传输和处理。

### 总结

- **核心要点**：数据系统的编码与演化是一个复杂但关键的问题，需设计灵活适应变化的系统，保持双向兼容性，选择合适的编码格式应对模式变化，确保数据在不同存储和通信场景中的稳定性和可用性。
- **实际应用**：在实际工作中，根据应用程序需求和场景，选择合适的编码格式，应用兼容性策略，解决数据编码和演化中的具体问题，保障系统的平稳运行和演进。

### 重点概念回顾

- **双向兼容性**：新代码读旧数据，旧代码读新数据。
- **常见编码格式**：JSON、XML、Protocol Buffers、Thrift、Avro。
- **Avro 模式**：作者模式（Writer's Schema）、读者模式（Reader's Schema）及兼容性规则。
- **数据存储和通信**：REST、RPC、消息传递系统（Actor、消息队列）。

### 实践建议

- **设计时考虑未来变化**：在构建数据系统时，预留空间和机制应对未来可能的功能变更和数据格式调整。
- **实现兼容性策略**：在系统演进过程中，应用具体兼容性策略，如添加默认值字段、使用字段别名等，确保数据的一致性和可用性。
