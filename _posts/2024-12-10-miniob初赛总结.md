---
layout: post
title: "24年miniob初赛总结"
date:   2024-12-10
tags: [OceanBase, Miniob]
comments: true
author: huanghuoguoguo
---

![](https://cdn.nlark.com/yuque/0/2024/png/32754462/1731130291786-db49232e-084f-4aab-bdab-3164e138f9fd.png)从八月中旬开始，就有在接触miniob的代码。尝试解决一些简单题。开赛后提交有60分。接下来简单讲讲题目的实现思路。

+ update。
+ date。
+ drop-table。
+ join-tables。
    - 实现表的全连接简单，但是join是有条件的。在on子句上，如果不做任何条件下推（下推到扫表时），那么复杂度太高，是过不去的。
    - 在创建物理计划的时候，将表两两连接成join。
    - 在optimize阶段将能够直接下推的表达式下推，比如join1.id>1这样的表达式直接下推至table_scan或者index_scan的阶段。避免无用连接笛卡尔积。
+ null、unique、mulit-index。
    - 这三个放在一起是因为后两个的用例会在null上建立。
    - 优先实现null。想要存储null，先要了解一行记录在磁盘上的存储方式，我们都知道具体的数据存储在磁盘上是字节，如果不引入额外的标志列来记录哪一列是null，那么只能规定特殊值代表此列是null。当然这个方法是不好的，所以最终选择新加一行隐藏列，暂时规定32位int来作为null列。在建表的时候，将其塞进去，之后判断该列是不是null的时候就检查该bitset，如果此位上是1，那么代表这一列是null。除此之外还需要修改为null时的tostring输出。
    - unique要修改b+树的比较策略。和mulit一起写了。首先将原先的单字段索引修改为多字段，用集合代替单fieldmeta。既然是多列比较，那么就要修改keycomperator，让其支持多列比较，并且是按字段顺序比较。和去年不同的是今年要考虑null列。所以要额外加入对null的判断。
    - 因为index不是全部的record数据，所以在往树中传的时候，要把要比较的字段信息都拿出来。构造新的data（注意还有null），往后传递。
    - 这里也说一个RID的概念，RID存储两个值，pagenumber和offset。这是diskbufferpool中用的。diskbufferpool还有frame和page的概念，一个page8192字节，和操作系统类似。
+ simple-sub，complex-sub。
    - 在题目中，simple是基本只有两层嵌套，complex有三层至四层。有feild in []，和 feild = select。
    - 表示形式：将subq视为表达式，yacc直接将其读取为node。然后在父stmt中创建和绑定。逻辑计划物理计划同理。
    - 改造value：因为还有in关键字，所以可以直接在绑定的时候将其提取。但是此时面临一个问题。虽然有子表达式了，但是try_get_value的返回值是一个value。in是一个操作符，所以只能通过将value改造为具备能够表达多个值的集合类型。这里的部分代码不讲，就是加标识，加功能。
    - 改造binder_context：子查询具备能够访问父查询的table和字段的能力。并且这是递归进行的。查找时优先查找当前层的字段，查不到才查父查询的字段。
+ update-select。
    - 就是update的时候获取的值为select提供。需要考虑null。
+ alias。
+ expression。
    - 表达式，其中可以做表达式下推，比如1=1，3+34/0这种。可以在优化阶段去掉。
    - 会和aggre交叉，需要考虑count，max，avg等没有结果集的情况（应该返回null或者0）。
+ orderby，aggre and group。
+ create-select。
+ view。
    - 由view的定义可以得知，这是一个逻辑表，view的定义来自几个table的集合，并且限制了对table的访问字段/或者得到新的由table的字段的表达式得到的列。同时，如果view是从单表创建并且没有表达式存在的情况下，可以update、insert、delete操作。
    - 由上述定义可以知道，view在逻辑上可以等同于table，只是加了一些限制。那么就可以用代理模式，增强其功能。具体做法是，用view继承table，并且view持有指向所需table的指针。重写table的所有方法。
    - 还需要修改程序启动时加载table的行为。view不真实存储数据。只需要存储view定义时的原数据或者sql即可。在打开程序的时候重放定义。
+ text，high-dim-vector。
+ vector。
    - 改造value。value中已经有一个union Val表示其存储的类型，由int，float，char*等。vector其实类似于一个集合，但是存储的都是float。基于此，我们可以将其放在一段字节中，用char*指向它，但是规定value的行为。新添加type Vector，实现其一系列方法即可。
    - 由于value的不可指向性，它构造新的value或者用赋值表达式时几乎都是新建一个对象。所以要做好内存的管理以及减少不必要的拷贝。具体可以参考一下字符串类型的value是怎么做的。
    - 需要注意从字符串转vector<float>时的效率问题，不要用regex。
+ vector-index。
    - 建立索引。继承index。但是实际上不实现也没关系，在orderby中完全可以实现，只是复杂度较高。
+ benchmark。
    - 官方要求的是建立倒排文件索引。一开始的时候的确是自己去实现一个朴素的倒排索引，用map建立索引，key_map存储键，每次查询**遍历**每个键，找到最接近的键，然后从最接近的5个键中，找到最近的limit个。但是这样会有什么问题，1：无法保证键都均匀分布，数据量是6w，245个簇，理想状态下每个簇有200+个向量，这样只需要比对245+5*200+约等于1300条即可找到答案。但是实际上是，如果是边插入边遍历索引，不仅效率慢（因为你要每插入一个就要调整质心），而且无法解决聚类的问题，除非实现分裂和合并。此时插入记录9min，建立索引40min。
    - 那么不能每插入一条数据就更新质心，这太频繁了。然后尝试当某个簇插入数据245条的倍数的时候调整质心，这依然不可用，因为簇会聚集，即使调整了质心后，仍然会出现聚集的情况。某个簇会出现有4000+条记录，某些簇会出现个位数的情况。
    - 一开始的想法是，变插入变建立索引，这样的话每个簇的质心只能是随机初始化（因为你不知道值域的上下界），然后在插入过程中逐个调整质心。后来证明这行不通。然后想到可以持有一部分数据后，通过kmeans聚类，然后再插入。但是仍然出现了聚类的问题，原因是当某个簇出现爆炸的时候，不能分裂（没有实现）。
    - 然后想到分裂，当某个簇大小超过两倍的簇容量时，将其一半分给容量最小的簇，然后更新质心，这仅能解决一部分问题，的确每个簇都能保持在250+左右，但是跑完之后召回率仅0.4，qps30+。原因显而易见，这么分配并不合理。
    - 然后想到，控制每次查询的总量，用最小堆，过程省略，这并不奏效。
    - 因为官方不限制第三方算法或者自己实现算法。所以在一开始其实有尝试直接用第三方建立，有google的fassi，但是gcc要求24+，而miniob的环境是22。这发生在优化之前。
    - 在经过上面一系列优化还距离目标非常遥远之时，再次尝试找第三方算法。此时，找到了一个header only的算法<font style="color:rgb(36, 41, 46);">HNSW</font>库。这是一个仅头文件的向量索引算法库，但是他没有实现ivfflat索引。我愿意尝试。
    - 引入之后，直接将6w条数据塞进去，的确。性能有了很大的提升，建立索引只需要3分钟，召回率来到了0.85+，qps60+。提测一波，还是失败。此时看到题目要求，1g-，100qps，10min内。
    - 有一个忘记提了，字符串转向量也是做了优化，之前用的是regex，插入9min，换成指针算法，优化后4min。
    - 用<font style="color:rgb(36, 41, 46);">HNSW</font>库建立6w数据的索引时，内存占用量达到了2.5g。这显然是不能接受的。而且在插入过程中，内存不断上涨，这显然是发生了内存泄漏。又开始从插入看起，把不必要的拷贝以及内存泄漏都接触后。内存占用1.5g。
    - 这还是不能接受，然后想到，虽然他不是ivfflat索引，但是能够利用他建立ivfflat索引。然后就出现了，簇键用ivfflat索引，簇内用ivfflat索引的方法。如果直接建立245个索引，每个会占据5m左右的内存，这也是不能接受的。后来发现把簇数量减少，召回率也没有下降。但是内存反而显著下降了。于是后面把索引个数控制在了60个，此时。召回率0.9，qps180。满足了要求。
+ update-mvcc。
    - 官方已经实现了mvcc的insert和delete。简而言之，插入的每一条数据，其实都保存在了磁盘上。不同条目的数据通过RID区分（pagenum，offsite），这是diskbufferpool所使用到的。
    - 那么是怎么控制不同的事务之间的可见性的呢？这就用到了两个关键的field。如之前的null_list用来控制字段的性质一样。在mvcc中也有两个字段用来表示可以看见此记录的事务id。称为begin_trx_id，end_trx_id。
    - 有些前置条件需要知道，每一次操作，如果不开启事务，会自动提交。每次执行前会申请一个trx_id。每个操作的record的事务字段会被更新。当一个事务要访问一条记录时，会进行比对，如果该事务id在[begin,end]之间，证明该record对该事务可见，那么如何界定begin和end呢？在插入时，会插入一条[cur_trx,-inf]的记录。在判断时，如果是第一种情况，直接可以访问，否则判断该记录是不是在当前事务范围内可见，通过其中一个字段是cur_trx来判断。
    - 而update的时候，因为事务未提交，所以需要保持原来的记录对其他事务可见，而新记录对当前事务可见，所以磁盘上会存有多个版本。并且不能直接删除原来的记录，只能通过trxid，使其不可见。
    - ![](https://cdn.nlark.com/yuque/0/2024/png/32754462/1731554505497-078561ea-e293-4b3a-8b49-945cc919b94b.png)
    - 未完待续。

