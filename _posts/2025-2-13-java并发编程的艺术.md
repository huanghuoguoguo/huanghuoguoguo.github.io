---
layout: post
title: "java并发编程的艺术"
date:   2025-2-13
tags: [java，并发编程]
comments: true
author: huanghuoguoguo
---

2.8开，2.11看完，2.13整理完毕。

# 第一章 并发编程的挑战

## 上下文切换

老生常谈的问题，频繁的上下文切换有时候可能比单线程更慢。上下文切换会使高速缓存失效，带来更多的缓存未命中。

### 多线程一定快吗

### 测试上下文切换次数和时长

### 如何减少上下文切换

无锁并发、CAS、最少线程和使用协程。

- 无锁并发：hash取模并发，使写操作互相不会争抢，降低锁粒度。比如jdk的并发map中的concuruntHashmap，redis分片集群通过hash槽分散写压力。
- CAS：原子操作，思想是争抢锁的时间是很短的。
- 最少线程：避免创建不需要的线程。
- 协程：单线程实现多任务的调度。

### 减少上下文切换实战

## 死锁

## 资源限制的挑战

什么是资源限制

资源限制引发的问题

如何解决资源限制的问题

在资源限制的情况下进行并发编程

## 本章小结

本章实际上是介绍了一些关于为什么要进行并发编程、它的好处与坏处、它面临的问题、代价成本的考虑、一些解决办法的思想的讨论。为之后的讨论打下基础。

# java并发机制的底层原理

这里进入JMM的范围，面试题常考。

## volatile的应用

### volatile的定义与实现原理

对于共享变量，使用过程中可能面临的问题。

- 现代计算机为了加速计算，会有工作内存。不能直接访问其他cpu的工作内存。
- 指令可能会被重排，如果没有依赖关系，可能会使用到尚未初始化的内存。
- 多线程情况下访问其他变量可能会未初始化。

一些术语：

- 内存屏障
- 缓冲行 cache line，得益于之前ob的比赛对sq4的优化，对缓冲行提前理解了一些。
- 原子操作
- 缓冲行填充
- 缓存命中
- 写命中
- 写缺失

volatile通过在字节码中嵌入lock保证可见性。

Lock前缀的指令在多核处理器下会引发两件事情：

- 将当前处理器缓存行的数据写回到系统内存。
- 这个写回内存的操作会使其他cpu里缓存了该内存地址的数据无效。

多核处理器会实现总线嗅探协议，保证数据被修改后的可见性。

### volatile的使用优化

考虑缓存行的填充，避免多核处理器对同一个缓存行（64字节）并发操作引起频繁失效。

## synchronized的实现原理与应用

### java对象头

mark word，class metadata address，array length（数组对象才有）

这种一个long内，int内，或者一个缓存行内嵌入信息很常见，紧凑的数据流传输，或者ob别人把c1数据嵌入到高32位，染色指针等等，都见过了。

这一节主要阐述了对象头存储的东西。怎么把诸多信息存储在32/64字节的对象头中，方便编码等等，需要考虑很多。

后面jdk几的版本将偏向锁默认关闭就是因为编码复杂。

### 锁的升级与对比

偏向锁，轻量级锁，重量级锁。锁可以升级不能降级。jvm设计者考虑的非常全面。

#### 偏向锁

偏向锁升级时，用cas设置对象头。

##### 偏向锁的撤销

有竞争时就会撤销偏向锁，升级为轻量级锁。

##### 关闭偏向锁

#### 轻量级锁

1. 无锁状态
   当一个对象没有被任何线程锁定时，它处于无锁状态。此时，对象头的Mark Word中存储的是对象的元数据信息。
2. 偏向锁（Biased Locking）
   定义与目的：偏向锁是一种针对单线程执行代码块的优化。其核心思想是，如果一个同步块被同一个线程多次访问，可以将锁偏向于该线程，避免每次进入同步块时的锁竞争开销。
   加锁机制：当第一个线程访问同步代码块时，JVM会将对象头的Mark Word设置为偏向锁，并记录该线程的ID。后续该线程再次访问时，只需检查Mark Word是否指向自己的线程ID。
   撤销与升级：当另一个线程尝试获取偏向锁时，偏向锁会被撤销，并升级为轻量级锁。
3. 轻量级锁（Lightweight Locking）
   定义与目的：轻量级锁适用于短暂的、低竞争的同步场景。它通过CAS操作和自旋等待来避免线程切换的开销。
   加锁机制：当偏向锁被撤销后，线程会在自己的栈帧中创建一个锁记录（Lock Record），并将对象头的Mark Word替换为指向该锁记录的指针。通过CAS操作尝试将Mark Word设置为指向锁记录的指针，如果成功，线程获得轻量级锁。
   升级条件：如果自旋尝试失败或自旋超过一定阈值（默认10次），轻量级锁会升级为重量级锁。
4. 重量级锁（Heavyweight Locking）
   定义与目的：重量级锁涉及操作系统级别的互斥量（Mutex），适用于高竞争或锁占用时间较长的场景。
   加锁机制：当轻量级锁升级为重量级锁后，未获取到锁的线程会被挂起，进入等待队列。持有锁的线程执行完毕后，会唤醒队列中的下一个等待线程。
   锁升级过程总结
   无锁状态：对象未被任何线程锁定。
   偏向锁：第一个线程访问同步代码块时，锁升级为偏向锁。
   轻量级锁：当有其他线程尝试获取偏向锁时，偏向锁被撤销并升级为轻量级锁。
   重量级锁：如果轻量级锁的自旋次数超过阈值，锁升级为重量级锁。
5. 注意事项
   锁升级是不可逆的：一旦锁从低级别状态升级到高级别状态，就无法再降级。
   锁升级带来的开销：锁升级过程可能会带来一定的开销，特别是在竞争激烈的情况下，频繁的锁升级会导致性能下降。
   锁的选择策略：在设计多线程应用时，需要根据实际场景选择合适的锁策略，以减少不必要的锁升级。
   通过动态调整锁的粒度，JVM可以在不同的情况下选择最合适的同步策略，从而优化多线程环境下的性能。	

总的来说，偏向锁只有单线程使用，出现其他线程即升级为轻量级锁。当竞争激烈的时候，升级为重量级锁。

### 锁的优缺点对比

## 原子操作的实现原理

多了几个术语。

- 比较并交换。cas
- cpu流水线，pipeline，之前在ob直播中讲过这一优化方案，不过还是太高级了。
- 内存顺序冲突，多个cpu修改同个缓存行。导致清空流水线。

### 处理器如何实现原子操作

缓存加锁或者是总线加锁。跨总线、跨多个缓存行和跨页表的访问不能缓存锁定，而是总线锁定。

#### 使用总线锁保证原子性

#### 使用缓存锁保证原子性

### java如何实现原子操作

ABA

循环时间长开销大

只能保证一个共享变量的原子操作

#### 使用锁机制实现原子操作

## 本章小结

volatile和synchronized是并发基础，内存可见性。这章还简单说了一下多核cpu下的缓存行问题，说了volatile怎么解决这个问题。还说了一下cas。

# java内存模型

## java内存模型的基础

### 并发编程模型的两个关键问题

- 线程之间如何通信
- 线程之间如何同步

### java内存模型的抽象结构

java线程之间的通信由JMM控制，JMM决定一个线程对共享变量的写入何时对另一个线程可见。

由此可知，volitale，sync，final，内存屏障，本地内存，写缓冲区，都属于JMM回答的内容。

在内存屏障之前，确保写缓冲区的内容都被写回主内存。

本地内存是JMM的一个抽象概念，它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。

通信过程必须通过主内存，但是线程之间（cpu之间不是之间发送消息），而是使该缓存失效，然后去主内存load。

JMM通过控制主内存与每个线程之间的本地内存之间的交互，来为Java程序员提供内存可见性保证。

### 从源代码到指令序列的重排序

- 编译器优化的重排序
- 指令级并行的重排序
- 内存系统的重排序

### 并发编程模型的分类

cpu密集型，io密集型，这里其实没什么好说的。

数据依赖性都不可被重排。

- LoadLoad
- StoreStore
- LoadStore
- StoreLoad

### happens-before

并不一定意味着一个操作在另一个操作之前执行。

## 重排序

### 数据依赖性

### as-if-serial语义

不管怎么重排序，程序的执行结果不能被改变。

### 程序顺序规则

### 重排序对多线程的影响

可能会让多线程读取到尚未初始化的内存地址。

## 顺序一致性

### 数据竞争与顺序一致性

### 顺序一致性内存模型

### 同步程序的顺序一致性结果

### 未同步程序的执行特性

总线事务。

总线仲裁。

## volatile的内存语义

### volatile的特性

理解volatile特性的一个好方法是把对volatile变量的单个读写，看成是使用同一个锁对这些单个读写操作进行了同步。

- 对一个volatile变量的读，总是能获得它最后的写。
- 多指令操作可能不是原子的，就不能保证。

### volatile写-读建立的happens-before关系

### volatile内存语义的实现

### 为什么要增强volatile的内存语义

## 锁的内存语义

### 锁的释放-获取建立的happens-before关系

### 锁的释放和获取的内存语义

实际上有相同的内存语义，都需要保证对变量的**可见性**。

### 锁内存语义的实现

AQS

CAS具有与volatile相同的读写内存语义。

AQS-CAS-Unsafe

在Java中，CAS（Compare-And-Swap）操作和`volatile`变量都具有类似的内存语义，主要体现在以下几个方面：

#### 1. 内存可见性

`volatile`变量的写操作会将线程的工作内存中的变量值刷新到主内存中，确保其他线程能够看到最新的值。CAS操作在执行时，也会涉及对主内存的读取和写入操作，确保操作的原子性。因此，CAS操作和`volatile`变量的写操作都保证了内存的可见性。

#### 2. 禁止指令重排序

`volatile`变量的读写操作会插入内存屏障，防止指令重排序。CAS操作在底层实现时，也会通过内存屏障（如`lock`前缀指令）来禁止指令重排序。这意味着在CAS操作前后，编译器和处理器都不会对相关指令进行重排序，从而保证了操作的顺序性。

#### 3. 原子性

CAS操作本身是原子性的，它通过比较内存中的值和预期值来决定是否更新。虽然`volatile`变量的读写操作本身不保证原子性，但它们的读写操作是独立的，且通过内存屏障确保了操作的顺序性。因此，从内存操作的角度来看，CAS操作和`volatile`变量的读写操作都具有类似的内存语义。

#### 4. 内存屏障的作用

CAS操作在底层实现时，通常会使用`lock`前缀指令，该指令具有以下作用：

- 确保对内存的读-改-写操作原子执行。
- 禁止该指令与之前和之后的读和写指令重排序。
- 把写缓冲区中的所有数据刷新到内存中。

这些特性与`volatile`变量的内存语义非常相似，因此可以说CAS操作具有和`volatile`变量类似的内存语义。

#### 总结

CAS操作和`volatile`变量都通过内存屏障机制确保了内存的可见性和操作的顺序性，虽然它们的用途和实现方式有所不同，但在内存语义上具有相似性。CAS操作通过原子性保证了操作的完整性，而`volatile`变量通过内存屏障确保了读写操作的顺序性和可见性。



### Concurrent包的实现

## final域的内存语义

到这里为止看了很多的内存语义。内存语义是什么意思？

#### 写final域的重排序规则

#### 读final域的重排序规则

#### final域为引用类型

### 为什么final域引用不能从构造函数中“逃逸”

可能会被其他线程访问到违背初始化的内存。

### final语义在处理器中的实现

### 为什么要增强final的语义

## happens-before

### JMM的设计

JMM允许不对程序结果影响的重排序。

### happens-before的定义

### happens-before规则

## 双重检查锁定与延迟初始化

### 双重检查锁的由来

sync的排队机制，可能会引发重复初始化。同时可能因为可见性，重排序引发未初始化内存访问。



### 问题的根源

分配对象的内存空间，设置instance指向内存空间，初始化对象，初次访问对象。

### 基于volatile的解决方案

保证可见性。禁止重排序。

### 基于类初始化的解决方案

在class被加载后，才执行初始化，而且由于加载类是线程安全的，只会被加载一次。所以可以用持有的方法，使只有第一次加载类的时候再进行初始化。

这里还介绍了类初始化的几个阶段。使通过condition来同步的。也是维护state。但是具体看jvm的实现。

## Java内存模型综述

这一节就指导着当被问到对JMM内存模型的理解时，从哪几个方面进行回答。

从硬件说起，cpu的内存模型，然后讲到JMM语言级别的内存模型。他们如何配合使用。lock指令，

### 处理器的内存模型

处理器会对指令重排序，而且多处理器下为了提高io会有工作内存的存在，不同的cache line之间有同步问题。怎么做线程之间的通知，线程之间怎么交互？这里是需要考虑的问题。内存锁定，总线锁定等等。

JMM屏蔽了不同处理器内存模型的差异，它在不同的处理器平台之上为java程序员了一个一致的内存模型。

### 各种内存模型之间的关系

JMM是一个语言级别的内存模型，处理器内存模型是硬件级的内存模型，顺序一致性内存模型是一个理论参考模型。

### JMM的内存可见性保证

### JSR-133对旧内存模型的修补

## 本章小结

从硬件到软件，从cpu到volatile语义。为了增强io带宽和提升并发度，有工作内存本地内存的概念，提升了单向的带宽，还需要增强横向的通信，保证数据安全性，不能被互相覆盖。那就需要线程间通信，线程间通过主内存进行通信，我的修改只是让其失效，类似业务redis缓存，我不更新缓存，我只是将其删除，等下一个业务查询的时候，才会去从数据库load出来。

那么当说到JMM的时候，应该说到哪些内容呢？volatile和synchronized的内存语义，多处理器下的内存通信，final，happens-before，各种内存屏障，重排序的影响等。

当讨论Java内存模型（JMM）时，以下内容是需要涵盖的关键点：

### 1. **主内存与工作内存**

- **主内存**：所有线程共享的内存区域，存储了所有共享变量的实例。
- **工作内存**：每个线程私有的内存区域，存储了该线程使用的共享变量的副本。线程对共享变量的操作必须在工作内存中进行，不能直接操作主内存中的变量。

### 2. **线程间通信**

- 线程间的数据交换必须通过主内存来完成。一个线程修改了共享变量的值，需要将修改后的值刷新到主内存；另一个线程需要读取共享变量时，必须从主内存中加载最新的值。

### 3. **内存可见性**

- `**volatile**`**关键字**：`volatile`变量的写操作会立即将值刷新到主内存，读操作会从主内存中读取最新的值，确保了不同线程对`volatile`变量的读写具有可见性。
- `**synchronized**`**关键字**：`synchronized`不仅提供了互斥锁的功能，还确保了内存的可见性和有序性。当线程进入`synchronized`块或方法时，会清空工作内存中该对象的属性，直接从主内存加载；退出时，则会将工作内存中的变更刷新回主内存。

### 4. **原子性与有序性**

- **原子性**：`synchronized`和`volatile`都保证了操作的原子性。`synchronized`通过锁机制确保同一时刻只有一个线程可以执行同步代码块，`volatile`则通过内存屏障确保读写操作的原子性。
- **有序性**：`synchronized`和`volatile`都通过内存屏障和锁机制防止指令重排序，确保操作的有序性。

### 5. `**final**`**字段的内存语义**

- `final`字段在构造对象时一旦被初始化，其值就不应该再被改变。JMM通过禁止指令重排序，确保了在对象构造完成（构造函数返回）之前，所有`final`字段都被正确初始化，这对于安全发布对象至关重要。

### 6. **Happens-Before原则**

- **Happens-Before原则**是JMM中用于定义操作之间顺序关系的关键原则。它确保了一个操作对另一个操作的可见性。常见的Happens-Before关系包括：

- 程序中的`volatile`变量写操作 happens-before 该变量的读操作。
- 在`lock`释放时 happens-before 同一锁的`unlock`操作。
- 在`Thread.start()`调用发生 happens-before 该线程的`run()`方法执行。

### 7. **内存屏障**

- **内存屏障**（Memory Barrier）是一种特殊的指令，用于控制内存操作的顺序，防止编译器和处理器对指令进行重排序。常见的内存屏障包括：

- **LoadLoad Barrier**：确保第一个加载操作的结果在第二个加载操作之前完成。
- **LoadStore Barrier**：确保加载操作的结果在存储操作之前完成。
- **StoreLoad Barrier**：确保存储操作的结果在加载操作之前完成。
- **StoreStore Barrier**：确保第一个存储操作的结果在第二个存储操作之前完成。

### 8. **重排序的影响**

- **重排序**是指编译器和处理器为了优化性能，可能会对指令的执行顺序进行调整。JMM通过内存屏障和锁机制来防止重排序，确保操作的顺序性和可见性。

### 9. **多处理器下的内存通信**

- 在多处理器环境下，每个处理器都有自己的缓存，可能会导致缓存不一致的问题。JMM通过内存屏障和锁机制确保多处理器之间的内存通信，保证数据的一致性和可见性。

### 10. **数据安全性**

- **数据安全性**是指在多线程环境下，确保数据不会被互相覆盖或导致不一致。JMM通过`volatile`、`synchronized`和内存屏障等机制，确保线程间的操作具有可见性和有序性，从而保证数据的安全性。

### 补充内容

- **工作内存与主内存的交互**：工作内存是每个线程私有的内存区域，存储了该线程使用的共享变量的副本。主内存是所有线程共享的内存区域，存储了所有共享变量的实例。线程间的数据交换必须通过主内存来完成。
- **线程间通信**：线程间的数据交换必须通过主内存来完成。一个线程修改了共享变量的值，需要将修改后的值刷新到主内存；另一个线程需要读取共享变量时，必须从主内存中加载最新的值。
- **数据安全性**：通过`volatile`、`synchronized`和内存屏障等机制，确保线程间的操作具有可见性和有序性，从而保证数据的安全性。

通过以上内容，可以全面理解JMM中的关键概念和机制，以及它们如何确保多线程环境下的数据一致性和安全性。

# java并发编程基础

## 线程简介

### 什么是线程

### 为什么要使用多线程

更多的处理器核心

更快的响应时间

更好的编程模型

### 线程优先级

### 线程的状态

### Daemon线程

## 启动和终止线程

很喜欢考start和run的区别。

### 构造线程

### 启动线程

### 理解中断

### 过期的suspend、resume、stop

### 安全的终止线程

线程不会被强行终止，线程只能自己检查退出，或者在wait状态下接收到终止信号然后抛出异常。

## 线程间通信

### volatile和synchronized关键字

之前已经提到过了，他们可以通过行为，通过第三方，对状态的影响进行通信。比如将状态置为1或者0，对其他线程保持可见性，然后可以影响其他线程的行为。

### 等待通知机制

轮询不是好的通知机制。

wait，notify。在Object上的方法。

调用wait进入等待队列，被唤醒进入同步队列。

### 等待通知的经典范式

等待方（消费者）

- 获取对象的锁
- 条件不满足，进入wait，被通知（醒来进入同步队列）后仍然要检查条件（while），不满足再进入wait
- 条件满足执行相应逻辑

通知方（生产者）

- 获取对象的锁
- 改变条件
- 通知消费者

### 管道输入、输出流

### thread.join()的使用

### ThreadLocal的使用

绑定在当前线程上的数据，threadlocalmap。这里虽然会经常靠，但是还是先放着。

## 线程应用实例

### 等待超时模式

wait可以添加超时时间。

### 一个简单的数据库连接池示例

### 线程池技术及其示例

线程池是很常用接触很多的技术了。

execute，submit

### 一个基于线程池技术的简单web服务器

提供tcp或者http连接的服务器一般都会将io连接的socket放到一个队列里。然后由worker线程池逐个取出进行消费。

在tomcat8之后，也和redis一样使用了io多路复用的技术了，这里仅仅是对io socket使用了多路，在处理请求的时候redis还是单线程，tomcat还是1对1。

## 本章小结

简单说了线程的概念，怎么启动和终止线程，线程间切换和通信的基础，操作系统和编程语言的支持。经典的线程间合作通信的例子。还讲了一下线程应用的示例。

# java中的锁

## Lock接口

Lock接口有synchronized关键字不具备的特性

- 公平非公平
- 能被中断的获取锁
- 超时获取锁
- Condition

### 1. `Lock`接口

`Lock`接口本身并不是基于`CAS`实现的。`Lock`接口定义了锁的基本操作，如`lock()`、`unlock()`等，但它只是一个接口，具体的实现类（如`ReentrantLock`）决定了锁的实现方式。`ReentrantLock`等锁的实现可能会使用`AQS`来管理线程的同步。

### 2. `AQS`（AbstractQueuedSynchronizer）

`AQS`是Java并发包中的一个核心类，许多同步器（如`ReentrantLock`、`Semaphore`、`CountDownLatch`等）都是基于`AQS`实现的。`AQS`使用了一个整数`state`来表示同步状态，并通过`CAS`操作来原子地修改这个状态。

`AQS`的核心机制包括：

- **独占锁**：通过`tryAcquire`和`tryRelease`方法实现。
- **共享锁**：通过`tryAcquireShared`和`tryReleaseShared`方法实现。
- **队列管理**：`AQS`维护了一个先进先出（FIFO）的队列，用于管理等待获取锁的线程。

`AQS`在实现中确实使用了`CAS`操作来保证线程安全，例如在修改`state`时会使用`compareAndSetState`方法。

### 3. `CAS`（Compare-And-Swap）

`CAS`是一种非阻塞的原子操作，用于在多线程环境中安全地更新变量。`CAS`操作需要三个参数：内存地址、预期值和新值。它会检查内存地址中的值是否等于预期值，如果是，则将新值写入该地址。

`CAS`操作在Java中是通过`Unsafe`类实现的。`Unsafe`类提供了一系列底层操作，包括`compareAndSwapInt`、`compareAndSwapLong`等方法，这些方法直接调用CPU的原子指令（如`cmpxchg`）来实现`CAS`操作。

### 4. `Unsafe`

`Unsafe`类是Java中一个非常底层的类，提供了直接操作内存和执行底层操作的能力。`Unsafe`类在`AQS`的实现中扮演了关键角色，尤其是在实现锁和条件变量时。`AQS`使用`Unsafe`提供的`CAS`方法来原子地修改同步状态`state`。

- `**Lock**`**接口**：定义了锁的基本操作，具体实现类（如`ReentrantLock`）可能基于`AQS`实现。
- `**AQS**`：基于`CAS`操作实现同步机制，使用`Unsafe`提供的`CAS`方法来保证线程安全。
- `**CAS**`：通过`Unsafe`类实现，是一种非阻塞的原子操作。
- `**Unsafe**`：提供了底层操作，包括`CAS`，是`AQS`实现的基础之一。

因此，`AQS`是基于`CAS`实现的，而`CAS`是通过`Unsafe`类实现的。

## 队列同步器

AbstractQueuedSynchronizer同步器。

带有状态的同步器，通过内置的FIFO队列完成资源获取线程的排队工作。

### AQS（AbstractQueuedSynchronizer）是带有状态的同步器

- **状态管理**：`AQS`通过一个`volatile int state`字段来管理同步状态。这个状态表示当前同步器的状态，如锁是否被持有、信号量的可用许可数量等。不同类型的同步器可以通过重写`AQS`的`tryAcquire`、`tryRelease`等方法来定义对同步状态的操作。
- **队列管理**：`AQS`内部维护了一个先进先出（FIFO）的双向队列，用于管理请求资源的线程。当线程请求资源无法立即满足时，会被封装成一个`Node`（节点）加入队列中等待。队列中的线程在适当的时机会被唤醒并重新尝试获取资源。

### AQS 的工作原理

1. **线程竞争资源**：

- 当一个线程请求共享资源时，`AQS`会调用`tryAcquire`方法尝试获取同步状态。
- 如果`tryAcquire`返回`true`，表示同步状态获取成功，线程可以继续执行。
- 如果返回`false`，线程会被封装成一个`Node`节点并加入队列。

1. **线程等待**：

- 加入队列的线程会处于等待状态，直到资源可用或被其他线程唤醒。
- `AQS`通过`LockSupport.park()`方法使线程暂停执行。

1. **资源释放**：

- 当持有资源的线程释放资源时，会调用`tryRelease`方法释放同步状态。
- 成功释放后，`AQS`会唤醒队列中等待的线程，被唤醒的线程会重新尝试获取资源。

1. **条件队列**：

- 对于复杂的同步需求，`AQS`还支持条件队列（`Condition`）。线程可以等待特定条件的发生，当条件满足时，线程会被唤醒。

### 例：ReentrantLock 的实现

`ReentrantLock`是基于`AQS`实现的。它通过以下步骤管理锁：

- 调用`lock()`方法时，`AQS`尝试获取同步状态。如果获取成功，线程继续执行。
- 如果获取失败，线程被封装成一个节点加入队列。
- 当锁被释放时，`AQS`唤醒队列中的下一个线程，被唤醒的线程再次尝试获取锁。

### 总结

`AQS`作为核心同步工具类，为Java并发包中的同步器（如`ReentrantLock`、`Semaphore`、`CountDownLatch`等）提供了底层支持。它通过状态和队列机制，以高效、灵活的方式管理线程对共享资源的竞争，确保同步的安全性和高效性。

### 队列同步器的接口与示例

主要是通过AQS操作其状态。

先想想AQS和`synchronized`的区别。两者的本质区别是什么？`synchronized`是Java语言层面的关键字，而AQS是Java并发库中一个更底层的实现类。`synchronized`是相对简单的，它的行为是固定的：加锁、解锁，直接操作对象头里的内容，或者同步块的入口出口。而AQS则更灵活，它可以让我们自己定义锁的行为——比如实现一个可重入锁、信号量，或者更复杂的同步结构。

AQS的核心确实是一个`state`变量，这个变量可以被各种同步器使用，不同的同步器会根据自己的需求定义这个变量的意义。比如`ReentrantLock`中，`state`表示锁被持有次数，而`Semaphore`中，`state`表示可用的许可数量。啊，这里得强调一下“CAS”操作，因为AQS通过`state`变量的原子性变化来控制线程的同步行为。每次线程去获取锁时，实际上是尝试使用`CAS`去更新这个`state`，如果成功了，就说明锁被获取；如果没有成功，线程就会被挂起等待。

另外，AQS的队列机制也很重要。当一个线程无法立即获取锁时，它会被放到AQS的等待队列中，这个队列是FIFO的顺序。这其实和操作系统中的线程调度有点类似，只是这里是针对用户态线程的，由Java虚拟机来管理。每次有线程释放资源，AQS就会唤醒队列中的下一个线程，让它重新尝试获取锁。这种机制保证了线程间的公平性，也让同步的实现更加高效。

比如用`ReentrantLock`来说明AQS的状态管理。`ReentrantLock`中的状态变量`state`其实代表了锁的持有次数。当一个线程第一次获取锁时，`state`会被设置为1；如果同一个线程再次获取锁（因为这个锁是可重入的），`state`就会加到2，依此类推。当线程释放锁时，`state`就会减1，直到减到0，这时其他线程就可以尝试获取锁了。这种通过`state`表示锁状态的方式，其实是AQS的一个核心设计。

- tryAcquire
- tryRelease
- tryAcquireShared
- tryReleaseShared
- isHeldExclusively

### 队列同步器的实现分析

#### 同步队列

当线程获取同步状态失败时，同步器会将当前线程以及等待状态等信息构成一个节点Node将其加入同步队列。同时阻塞当前线程，当同步状态释放时，会把首节点线程唤醒，使其再次尝试获取同步状态。

wait会进入等待队列而不是同步队列。

AQS中的同步队列和monitor（synchronized关键字中的同步队列和等待队列有什么区别呢？）

#### AQS 的同步队列与 `monitor` 中的队列对比

- **同步队列（Synchronization Queue）**：

- **AQS 的同步队列**：

- 是一个 FIFO 的双向队列，用于管理等待获取同步状态的线程。
- 线程在尝试获取同步状态（如锁）失败后，会被封装成一个 `Node` 节点并添加到队列尾部，同时线程被阻塞。
- 当同步状态释放时，释放锁的线程会唤醒队列中的首节点线程，使其重新尝试获取同步状态。
- 该队列中的线程都是在等待获取某种同步资源，例如锁、信号量等。
- 是显式维护的，由 AQS 框架直接管理。

- `**monitor**` **的同步队列（Entry Queue）**：

- `monitor` 是与 `synchronized` 关键字相关的同步结构。
- `monitor` 内部维护一个 Entry Queue，用于存放等待进入 `monitor` 的线程。
- 当线程尝试进入 `synchronized` 代码块但无法获取锁时，会被挂起并放入 Entry Queue。
- 当锁被释放时，`monitor` 会选择一个线程从 Entry Queue 移出，并允许其尝试获取锁。
- 该队列是隐式维护的，由 JVM 自动管理，无需开发者干预。

- **等待队列（Wait Queue）**：

- **AQS 的等待队列**：

- AQS 并未直接提到或管理 “等待队列”，它的核心在于同步队列。
- 如果需要实现类似于 `wait` 和 `notify` 的功能时，通常会使用 `Condition` 对象来实现。`Condition` 对象内部会维护一个等待队列。

- `**monitor**` **的等待队列（Wait Set）**：

- `monitor` 中维护一个 Wait Set，用于存放调用 `wait()` 方法而被挂起的线程。
- 当线程因调用 `wait()` 方法而暂停执行时，会移动到 Wait Set。
- 当其他线程调用 `notify()` 或 `notifyAll()` 方法时，`monitor` 会唤醒 Wait Set 中的一个或多个线程，使其重新进入同步队列，竞争锁。

#### 总结对比

| **特性**     | **AQS 的同步队列**                                         | `**synchronized**` **的 Entry Queue 和 Wait Set**            |
| ------------ | ---------------------------------------------------------- | ------------------------------------------------------------ |
| **类型**     | 同步队列                                                   | Entry Queue 和 Wait Set                                      |
| **目的**     | 管理等待获取同步状态的线程                                 | 管理等待进入对象锁（Entry Queue）和等待条件（Wait Set）的线程 |
| **线程状态** | 等待获取锁或释放锁                                         | 等待进入锁（Entry Queue）或等待条件满足（Wait Set）          |
| **管理方式** | 由 AQS 显式维护，通过节点（`Node`）构成队列                | 由 JVM 隐式维护，无需开发者直接操作                          |
| **灵活性**   | 高，可扩展为各种同步器（如锁、信号量）                     | 低，功能固定，局限于 `synchronized` 的语义                   |
| **应用场景** | 用于实现复杂的同步控制，如 `ReentrantLock`、`Semaphore` 等 | 用于简单的同步代码块或方法                                   |

通过以上对比，可以看出 `AQS` 的同步队列和 `monitor` 的队列机制在设计目的、管理方式和灵活性等方面存在显著差异。AQS 提供了更灵活的同步控制和更丰富的功能，而 `synchronized` 的队列机制则更简单、直接，适用于基础的同步需求。

#### 独占式同步状态获取与释放

在 AQS（AbstractQueuedSynchronizer）中，节点（`Node`）代表线程，但线程的状态并不都是 `wait`。线程在 AQS 中的状态和行为取决于其在同步队列中的位置和锁的获取情况。以下是关于 AQS 中线程状态和唤醒机制的详细说明：

##### 线程状态

- **自旋等待**：当线程尝试获取锁失败时，它会先进入自旋等待状态。自旋等待是指线程在循环中不断尝试获取锁，而不是立即进入阻塞状态。这种机制可以减少线程的阻塞和唤醒操作，提高性能。
- **阻塞等待**：如果自旋等待超过一定时间（通常是系统设定的自旋阈值），线程会进入阻塞状态，并被加入到同步队列中。线程在阻塞状态下不会消耗 CPU 资源，直到被唤醒。

##### 唤醒机制

- **锁的释放和唤醒**：当持有锁的线程释放锁时，AQS 会唤醒同步队列中的下一个等待线程，让它尝试获取锁。这个过程是通过 `LockSupport.unpark()` 方法实现的。
- **节点状态**：AQS 中的节点（`Node`）会记录线程的状态，包括是否被阻塞、是否等待等。节点的状态会影响线程的唤醒和调度。

##### 自旋等待和唤醒的细节

- **自旋等待前一个节点是否为 head**：线程在自旋等待时，会检查前一个节点是否为 `head` 节点。如果前一个节点成为 `head` 节点，说明它已经获取到了锁，当前线程有机会获取锁。
- **节点自己唤醒**：线程在被唤醒后，会重新尝试获取锁。如果获取成功，线程会继续执行；如果获取失败，线程可能会再次进入自旋等待或阻塞状态。

##### 总结

- AQS 中的线程在获取锁失败时，会先进入自旋等待状态，而不是直接进入阻塞状态。
- 线程在自旋等待时会检查前一个节点是否为 `head` 节点，以判断是否有机会获取锁。
- 当锁被释放时，AQS 会唤醒同步队列中的下一个等待线程，让它尝试获取锁。
- 线程在被唤醒后，会重新尝试获取锁，而不是由其他节点唤醒。

这种机制确保了线程在等待锁时能够高效地利用 CPU 资源，同时保证了线程的公平性和同步的正确性。

**节点会以死循环的方式获取同步状态，如果获取不到则阻塞节点中的线程，而被阻塞线程的唤醒主要依靠前驱节点的出队或阻塞线程被中断来实现。**

### AQS 的同步队列中的线程和 `monitor` 的同步队列中的线程状态

- **AQS 的同步队列中的线程状态**：

- 在 AQS 的同步队列中，线程的状态可以是 `WAITING` 或 `TIMED_WAITING`，具体取决于线程是否被阻塞以及是否设置了超时时间。
- 当线程尝试获取锁失败时，它会被封装成一个 `Node` 节点并加入同步队列。如果线程在自旋等待后仍然无法获取锁，它会被阻塞并进入 `WAITING` 状态。
- AQS 使用 `LockSupport.park()` 方法来阻塞线程，线程在被阻塞时会进入 `WAITING` 状态。

- `**monitor**` **的同步队列中的线程状态**：

- 在 `monitor` 的同步队列中，线程的状态也是 `WAITING`，但这是由 JVM 自动管理的。
- 当线程尝试进入 `synchronized` 代码块但无法获取锁时，它会被挂起并放入 `monitor` 的同步队列。
- 线程在 `monitor` 中的状态是由 JVM 管理的，开发者无法直接控制。

#### 使用 `park` 进行阻塞和 `wait` 的区别

- `**park**` **方法**：

- `park` 方法是 `LockSupport` 类中的方法，用于阻塞当前线程。
- `park` 方法可以指定超时时间，线程在超时后会自动唤醒。
- `park` 方法的阻塞是可中断的，线程可以在被中断时唤醒。

- `**wait**` **方法**：

- `wait` 方法是 `Object` 类中的方法，用于让当前线程释放锁并进入等待状态。
- `wait` 方法必须在同步代码块或同步方法中调用，线程在调用 `wait` 方法后会释放锁并进入 `WAITING` 状态。
- `wait` 方法的阻塞是可中断的，线程能在被其他线程调用 `notify` 或 `notifyAll` 方法时唤醒，也能被调用interupt方法打断抛出异常。

#### 总结

- **线程状态**：

- AQS 的同步队列中的线程状态可以是 `WAITING` 或 `TIMED_WAITING`，具体取决于线程是否被阻塞以及是否设置了超时时间。
- `monitor` 的同步队列中的线程状态也是 `WAITING`，但这是由 JVM 自动管理的。

- **阻塞机制**：

- AQS 使用 `LockSupport.park()` 方法来阻塞线程，线程在被阻塞时会进入 `WAITING` 状态。
- `monitor` 使用 `wait` 方法来阻塞线程，线程在调用 `wait` 方法后会释放锁并进入 `WAITING` 状态。

#### 共享式同步状态获取与释放

#### 独占式超时获取同步状态

## 重入锁

ReentrantLock

- 实现冲入
- 公平锁与非公平锁的区别

- 在首次获取锁的时候，非公平锁会用CAS尝试获取，而公平锁会直接进入等待队列。唤醒时也是从同步队列取出。
- 公平锁在尝试获取锁时，会检查同步队列中是否有其他线程正在等待。如果有等待的线程，当前线程不会直接尝试获取锁，而是会将自己加入到同步队列的末尾，等待被唤醒。
- 非公平锁在尝试获取锁时，会直接使用 `CAS`（Compare-And-Swap）操作尝试获取锁。如果获取成功，则直接运行；如果获取失败，才会将自己加入到同步队列中等待。
- 非公平锁性能较高。

## 读写锁

锁降级的概念。

### 读写锁的接口与示例

### 读写锁的视线分析

- 读写状态的设计

- 状态融合，用字节融合表示状态。使判断操作原子。

- 写锁的获取与释放
- 锁降级

- 获取到写锁之后，降级到读锁。

## LockSupport工具

park不会释放锁，wait会。

## Condition接口

### 接口与示例

Lock.newCondition()

await和wait，signal和notify

### Condition的实现分析

#### 等待队列

FIFO，node复用了同步器AQS的定义。

一个condition包含一个等待队列。

一个同步器Lock有一个同步队列和多个等待队列。等待队列只能进入同步队列。同步队列才能获取锁。也就是说，线程进入等待队列后，被notify，转移至同步队列去争抢锁，如果不满足条件，会再被投入等待队列（重新构造了node节点加入到队尾）。也只有获取到锁的线程可以await。

#### 等待

#### 通知

调用Condition的signal方法，会唤醒在等待队列中等待时间最长的节点（首节点），在唤醒节点之前，会将节点移动到同步队列中。

signalAll方法相当于对等待队列中的每个节点都进行一次signal，效果就是将等待队列中所有节点全部移动到同步队列中，并唤醒每个节点的线程争抢同步锁。

## 本章小结

Lock->AQS->CAS->Unsafe，ReentrantLock，信号量等基于AQS，还讲了一下Lock接口的Condition，LockSupport工具



# Java并发容器和框架

## ConcurrentHashMap

回答几个点：

- segment段锁到数组+链表红黑树，更细粒度的锁，提供更高的性能。
- 渐进式hash，扩容时的多线程并发扩容转移。同时有copy on write的思想，先查询旧的，查询不到再去新的。同时有标识标志是否正在扩容。
- 曾经有bug，导致链表头插法成环。

### 为什么要用它？

线程不安全的hashmap

效率低下的hashtable

锁分段有效。

这是数据密集型里面说的，数据hash分段之后可以减少冲突。

和redis的分片一样。

### 结构

segment数组。hashentry，reentrantlock

### 定位segment

通过散列算法定位到segment。

### 操作

## ConcurrentLinkedQueue

CAS

## java中的阻塞队列

## Fork、Join框架

### 工作窃取算法

这个在caffine的common线程池中见到了。

### Fork、Join框架的设计

有点类似mapreduce，但并不是无状态的。

他也是将任务进行切割再组合。

### Fork、Join使用

### Fork、Join异常处理

任务是有状态的， 可以提供方法让程序员获取到。

### Fork、Join的实现原理

# java中的13个原子操作类

## 原子更新基本类

AtomicInteger和其他。

调用native的Unsafe方法。

## 原子更新数组

## 原子更新引用类型

## 原子更新字段类

## 本章小结

介绍了一下原子更新提供的方法，以及他们的实现原理。

# java中的并发工具类

在力扣刷多线程的题的时候，有的人就用很多种方法完成。本章结尾会抄过来。

作者：阿飞

链接：https://leetcode.cn/problems/print-foobar-alternately/solutions/895531/chang-you-duo-xian-cheng-zhi-1115-by-a-f-mf5u/

来源：力扣（LeetCode）

## 等待多线程完成的CountDownLatch

## 同步屏障cyclicBarrier

```java
public CyclicBarrier(int parties)
public CyclicBarrier(int parties, Runnable barrierAction)
// -构造方法
//parties 是参与线程的个数
//第二个构造方法有一个 Runnable 参数，这个参数的意思是最后一个到达线程要做的任务
---
public int await() throws InterruptedException, BrokenBarrierException
public int await(long timeout, TimeUnit unit) throws InterruptedException, BrokenBarrierException, TimeoutException
//- 函数
//线程调用 await() 表示自己已经到达栅栏
//BrokenBarrierException 表示栅栏已经被破坏，破坏的原因可能是其中一个线程 await() 时被中断或者超时
//调用await方法的线程告诉CyclicBarrier自己已经到达同步点，然后当前线程被阻塞。直到parties个参与线程调用了await方法
```

CyclicBarrier 与 CountDownLatch 区别

CountDownLatch 是一次性的，CyclicBarrier 是可循环利用的

CountDownLatch 参与的线程的职责是不一样的，有的在倒计时，有的在等待倒计时结束。CyclicBarrier 参与的线程职责是一样的

```java
static class _5th_2 {

    //input
    public static void main(String[] args) {
        FooBar fooBar = new FooBar(10);//打印10次foo bar
        Runnable printFoo = () -> {
            System.out.printf("%s\n", "foo");
        };
        Runnable printBar = () -> {
            System.out.printf("%s\n", "bar");
        };
        Thread fooThread = new Thread(() -> {
            try {
                fooBar.foo(printFoo);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        });
        Thread barThread = new Thread(() -> {
            try {
                fooBar.bar(printBar);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        });
        fooThread.start();
        barThread.start();

    }

    static class FooBar {
        private int n;

        private CyclicBarrier cb = new CyclicBarrier(2);
        volatile boolean fooExec = true;

        public FooBar(int n) {
            this.n = n;
        }

        public void foo(Runnable printFoo) throws InterruptedException {

            for (int i = 0; i < n; i++) {
                while (!fooExec) {
                    //false的时候，bar线程在执行，foo线程在这此处空转
                }
                printFoo.run();//打印foo
                fooExec = false;//设置变量
                try {
                    cb.await();//线程foo到达同步点
                } catch (BrokenBarrierException e) {
                    e.printStackTrace();
                }
            }
        }

        public void bar(Runnable printBar) throws InterruptedException {

            for (int i = 0; i < n; i++) {
                try {
                    cb.await();
                } catch (BrokenBarrierException e) {
                    e.printStackTrace();
                }
                printBar.run();
                fooExec = true;

            }
        }
    }
}
```



## 控制并发线程数的Semaphore

Semaphore是一个计数信号量。

从概念上将，Semaphore包含一组许可证。

如果有需要的话，每个acquire()方法都会阻塞，直到获取一个可用的许可证。

每个release()方法都会释放持有许可证的线程，并且归还Semaphore一个可用的许可证。

然而，实际上并没有真实的许可证对象供线程使用，Semaphore只是对可用的数量进行管理维护

总结：如果线程要访问一个资源就必须先获得信号量。如果信号量内部计数器大于0，信号量减1，然后允许共享这个资源；否则，如果信号量的计数器等于0，信号量将会把线程置入休眠直至计数器大于0.当信号量使用完时，必须释放

```java
class FooBar {
    private int n;

    private Semaphore fooSema = new Semaphore(1);
    private Semaphore barSema = new Semaphore(0);

    public FooBar(int n) {
        this.n = n;
    }

    public void foo(Runnable printFoo) throws InterruptedException {

        for (int i = 0; i < n; i++) {
            fooSema.acquire();//值为1的时候，能拿到，执行下面的操作
            printFoo.run();
            barSema.release();//释放许可给barSema这个信号量 barSema 的值+1
        }
    }

    public void bar(Runnable printBar) throws InterruptedException {

        for (int i = 0; i < n; i++) {
            barSema.acquire();//值为1的时候，能拿到，执行下面的操作
            printBar.run();
            fooSema.release();//释放许可给fooSema这个信号量 fooSema 的值+1
        }
    }
}
```

## Thread.yield()

Thread.yield():使当前线程从执行状态（运行状态）变为可执行态（就绪状态）。cpu会从众多的可执行态里选择，也就是说，当前也就是刚刚的那个线程还是有可能会被再次执行到的，并不是说一定会执行其他线程而该线程在下一次中不会执行到了。

```java
class FooBar {
    private int n;

    volatile boolean fooExec = true;//foo可以执行

    public FooBar(int n) {
        this.n = n;
    }

    public void foo(Runnable printFoo) throws InterruptedException {

        for (int i = 0; i < n; ) {
            if (fooExec) {
                printFoo.run();
                fooExec = false;
                i++;
            } else {
                Thread.yield();
            }

        }
    }

    public void bar(Runnable printBar) throws InterruptedException {

        for (int i = 0; i < n; ) {
            if (!fooExec) {
                printBar.run();
                fooExec = true;
                i++;
            } else {
                Thread.yield();
            }

        }
    }
}
```

## ReentrantLock

### 背景知识

#### 实现原理

ReentrantLock主要利用CAS+AQS队列来实现。它支持公平锁和非公平锁，两者的实现类似。



CAS：Compare and Swap，比较并交换。CAS有3个操作数：内存值V、预期值A、要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。该操作是一个原子操作，被广泛的应用在Java的底层实现中。在Java中，CAS主要是由sun.misc.Unsafe这个类通过JNI调用CPU底层指令实现



ReentrantLock主要利用CAS+AQS队列来实现。它支持公平锁和非公平锁，两者的实现类似。



CAS：Compare and Swap，比较并交换。CAS有3个操作数：内存值V、预期值A、要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。该操作是一个原子操作，被广泛的应用在Java的底层实现中。在Java中，CAS主要是由sun.misc.Unsafe这个类通过JNI调用CPU底层指令实现



##### ReentrantLock和synchronized比较

- ReentrantLock和synchronized都是独占锁,只允许线程互斥的访问临界区。但是实现上两者不同:synchronized加锁解锁的过程是隐式的,用户不用手动操作,优点是操作简单，但显得不够灵活。一般并发场景使用synchronized的就够了；ReentrantLock需要手动加锁和解锁,且解锁的操作尽量要放在finally代码块中,保证线程正确释放锁。ReentrantLock操作较为复杂，但是因为可以手动控制加锁和解锁过程,在复杂的并发场景中能派上用场。
- ReentrantLock和synchronized都是可重入的。synchronized因为可重入因此可以放在被递归执行的方法上,且不用担心线程最后能否正确释放锁；而ReentrantLock在重入时要却确保重复获取锁的次数必须和重复释放锁的次数一样，否则可能导致其他线程无法获得该锁
- n=5的时候，已经显示TLE了

```java
class FooBar {
    private int n;
    private ReentrantLock lock = new ReentrantLock(true);
    volatile boolean fooExec = true;

    public FooBar(int n) {
        this.n = n;
    }

    public void foo(Runnable printFoo) throws InterruptedException {
        for (int i = 0; i < n; ) {
            lock.lock();
            try {
                if (fooExec) {
                    printFoo.run();
                    fooExec = false;
                    i++;
                }
            } finally {
                lock.unlock();
            }

        }
    }

    public void bar(Runnable printBar) throws InterruptedException {
        for (int i = 0; i < n; ) {
            lock.lock();
            try {
                if (!fooExec) {
                    printBar.run();
                    fooExec = true;
                    i++;
                }
            } finally {
                lock.unlock();
            }
        }
    }
}
```

## BlockingQueue

### 背景知识

- SynchronousQueue： 一个不存储元素的阻塞队列，每一个put操作必须等待take操作，否则不能添加元素。支持公平锁和非公平锁。SynchronousQueue的一个使用场景是在线程池里。Executors.newCachedThreadPool()就使用了SynchronousQueue，这个线程池根据需要（新任务到来时）创建新的线程，如果有空闲线程则会重复使用，线程空闲了60秒后会被回收。
- LinkedBlockingDeque： 一个由链表结构组成的双向阻塞队列。队列头部和尾部都可以添加和移除元素，多线程并发时，可以将锁的竞争最多降到一半
- add(obj):把obj加到BlockingQueue里,如果BlockQueue没有空间,则调用此方法的线程被阻断直到BlockingQueue里面有空间再继续.
- take():取走BlockingQueue里排在首位的对象,若BlockingQueue为空,阻断进入等待状态直到BlockingQueue有新的数据被加入;

```java
class FooBar {
    private int n;
    private BlockingQueue<Integer> fooQueue = new LinkedBlockingQueue<Integer>() {{
        add(0);
    }};
    private BlockingQueue<Integer> barQueue = new LinkedBlockingQueue<>();

    public FooBar(int n) {
        this.n = n;
    }

    public void foo(Runnable printFoo) throws InterruptedException {

        for (int i = 0; i < n; i++) {
            fooQueue.take();
            printFoo.run();
            barQueue.add(0);
        }
    }

    public void bar(Runnable printBar) throws InterruptedException {

        for (int i = 0; i < n; i++) {
            barQueue.take();
            printBar.run();
            fooQueue.add(0);
        }
    }
}
```

## synchronized

### 背景知识

- 1、wait()、notify/notifyAll() 方法是Object的本地final方法，无法被重写。
- 2、wait()使当前线程阻塞，前提是 必须先获得锁，一般配合synchronized 关键字使用，即，一般在synchronized 同步代码块里使用 wait()、notify/notifyAll() 方法。

- 3、 由于 wait()、notify/notifyAll() 在synchronized 代码块执行，说明当前线程一定是获取了锁的。

- 当线程执行wait()方法时候，会释放当前的锁，然后让出CPU，进入等待状态。
- 只有当 notify/notifyAll() 被执行时候，才会唤醒一个或多个正处于等待状态的线程，然后继续往下执行，直到执行完synchronized 代码块的代码或是中途遇到wait() ，再次释放锁。
- 也就是说，notify/notifyAll() 的执行只是唤醒沉睡的线程，而不会立即释放锁，锁的释放要看代码块的具体执行情况。所以在编程中，尽量在使用了notify/notifyAll() 后立即退出临界区，以唤醒其他线程让其获得锁

- 4、wait() 需要被try catch包围，以便发生异常中断也可以使wait等待的线程唤醒。
- 5、notify 和wait 的顺序不能错，如果A线程先执行notify方法，B线程在执行wait方法，那么B线程是无法被唤醒的。
- 6、notify 和 notifyAll的区别

- notify方法只唤醒一个等待（对象的）线程并使该线程开始执行。所以如果有多个线程等待一个对象，这个方法只会唤醒其中一个线程，选择哪个线程取决于操作系统对多线程管理的实现。notifyAll 会唤醒所有等待(对象的)线程，尽管哪一个线程将会第一个处理取决于操作系统的实现。如果当前情况下有多个线程需要被唤醒，推荐使用notifyAll 方法。比如在生产者-消费者里面的使用，每次都需要唤醒所有的消费者或是生产者，以判断程序是否可以继续往下执行。

- 7、在多线程中要测试某个条件的变化，使用if 还是while？

- 要注意，notify唤醒沉睡的线程后，线程会接着上次的执行继续往下执行。所以在进行条件判断时候，可以先把 wait 语句忽略不计来进行考虑；显然，要确保程序一定要执行，并且要保证程序直到满足一定的条件再执行，要使用while进行等待，直到满足条件才继续往下执行

```java
class FooBar {
    private int n;
    private Object obj = new Object();
    private volatile boolean fooExec = true;

    public FooBar(int n) {
        this.n = n;
    }

    public void foo(Runnable printFoo) throws InterruptedException {

        for (int i = 0; i < n; i++) {
            synchronized (obj) {
                if (!fooExec) {//fooExec为false时，该线程等待，为true的时候执行下面的操作
                    obj.wait();
                }
                printFoo.run();
                fooExec = false;
                obj.notifyAll();//唤醒其他线程
            }

        }
    }

    public void bar(Runnable printBar) throws InterruptedException {

        for (int i = 0; i < n; i++) {
            synchronized (obj) {
                if (fooExec) {
                    obj.wait();
                }
                printBar.run();
                fooExec = true;
                obj.notifyAll();
            }

        }
    }
}
```

## LockSupport

LockSupport类的核心方法其实就两个：park()和unpark()，其中park()方法用来阻塞当前调用线程，unpark()方法用于唤醒指定线程。

这其实和Object类的wait()和signal()方法有些类似，但是LockSupport的这两种方法从语意上讲比Object类的方法更清晰，而且可以针对指定线程进行阻塞和唤醒。

LockSupport类使用了一种名为Permit（许可）的概念来做到阻塞和唤醒线程的功能，可以把许可看成是一种(0,1)信号量（Semaphore），但与 Semaphore 不同的是，许可的累加上限是1。

初始时，permit为0，当调用unpark()方法时，线程的permit加1，当调用park()方法时，如果permit为0，则调用线程进入阻塞状态。

```java
class FooBar {
    private int n;
    private Map<String, Thread> map = new ConcurrentHashMap<>();
    private volatile boolean fooExec = true;

    public FooBar(int n) {
        this.n = n;
    }

    public void foo(Runnable printFoo) throws InterruptedException {
        map.put("foo", Thread.currentThread());
        for (int i = 0; i < n; i++) {
            while (!fooExec) {
                LockSupport.park();
            }
            printFoo.run();
            fooExec = false;
            LockSupport.unpark(map.get("bar"));
        }
    }

    public void bar(Runnable printBar) throws InterruptedException {
        map.put("bar", Thread.currentThread());
        for (int i = 0; i < n; i++) {
            while (fooExec) {
                LockSupport.park();
            }
            printBar.run();
            fooExec = true;
            LockSupport.unpark(map.get("foo"));
        }
    }
}
```

# java中的线程池

几个参数，几个框架提供的类。以及他们的使用方式。这里就不一一罗列了。

# Executor框架

这一章其实对我有一些启示，因为我正在尝试实现一个从公司的单体任务调度的框架迁移到分布式集群的任务框架的任务。

有以下几个准则：

- 任务池的任务隔离：根据优先级，或者互斥，需要对任务的执行顺序做隔离。像公司的有状态的任务调度，下电可以优先于风扇风速的调整，这是显而易见的。
- 任务池的重试策略：根据不同的任务类型做不同的重试策略。参考像公司的job框架，实现了不同粒度的重试，phase的。那么我实现在单体任务上的phase重试，重试策略，重试抓取等等，不同机器上的重试则不生效。如果发生失败或者宕机主从转移的情况下，所有任务都将失败。
- 任务必须无状态：在公司的job框架上，它是有状态的，任务的分发，下达的命令，有的必须落到特定的机器上，比如调整风扇转速，跟特定硬件相关的情况下，不好做成无状态的，又不是计算任务。所以当引入到无状态的分布式任务调度的情况下，需要考虑到这个情况。

看完全书，对JMM，并发编程面临的问题，怎么使用优雅的方式一步一步优化有了更多的了解。
