---
layout: post
title: "hnsw大limt-分段堆优化"
date:   2025-1-5
tags: [OceanBase, 数据库, hnsw]
comments: true
author: huanghuoguoguo
---

<font style="color:rgb(25, 27, 31);">HNSW，即Hierarchical Navigable Small World graphs（分层-可导航-小世界-图）的缩写，可以说是在工业界影响力最大的基于图的</font>[<font style="color:rgb(25, 27, 31);">近似最近邻搜索算法</font>](https://zhida.zhihu.com/search?content_id=237691171&content_type=Article&match_order=1&q=%E8%BF%91%E4%BC%BC%E6%9C%80%E8%BF%91%E9%82%BB%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95&zhida_source=entity)<font style="color:rgb(25, 27, 31);">（Approximate Nearest Neighbor，ANN），没有之一。HNSW 是一种非常流行和强大的算法，具有超快的搜索速度和出色的</font>[<font style="color:rgb(25, 27, 31);">召回率</font>](https://zhida.zhihu.com/search?content_id=237691171&content_type=Article&match_order=1&q=%E5%8F%AC%E5%9B%9E%E7%8E%87&zhida_source=entity)<font style="color:rgb(25, 27, 31);">。</font>

<font style="color:rgb(25, 27, 31);">然而，尽管 HNSW 是一种用于ANN 的流行且稳健的算法，但要理解它的工作原理并不容易。</font>

![](https://huanghuoguoguo.github.io/images/hnsw-big-limit-1.png)

关于hnsw的介绍就不多费周章，接下来介绍赛题的优化和思路。

在ob国赛的赛题中，需要对大limit的标量索引进行优化。sql如下：

```plsql
-- 基础 ann_benchmarksSELECT id
FROM items1
ORDER BY L2_distance(embedding, vector)
approximate LIMIT xxx

-- 混合标量查询场景SELECT id
FROM items1
Where c1 = xxx
ORDER BY L2_distance(embedding, vector)
approximate LIMIT 10000
```

vsag的hnsw实现其实也是著名开源nmslib/hnsw实现。原始代码不帖了。

可以发现的是，原始代码只维护一个堆，在数据量较大（10000）时，每次调整堆，可能不能很好的利用cpu的高速缓存。入堆出堆大概是2*log10000 = 14，而采用分段堆之后，每次调整大概是4*log100=14，虽然复杂度看起来一样，但是每次调整的下标很接近，所以很可能提高缓存性能。

接下来是具体的思路：

#### <font style="color:rgb(6, 6, 7);">1.</font><font style="color:rgb(6, 6, 7);"> </font>**<font style="color:rgb(6, 6, 7);">分段堆的引入</font>**
<font style="color:rgb(6, 6, 7);">在原始的HNSW实现中，维护一个全局的大堆来存储候选点。当数据量较大（如10000）时，每次调整堆可能会导致频繁的内存访问，难以充分利用CPU的高速缓存</font><font style="color:rgb(6, 6, 7);">。通过引入分段堆，将候选点分成多个小堆，每个堆的大小远小于全局堆，从而减少每次调整堆时的内存访问范围，提高缓存利用率</font><font style="color:rgb(6, 6, 7);">。</font>

#### <font style="color:rgb(6, 6, 7);">2.</font><font style="color:rgb(6, 6, 7);"> </font>**<font style="color:rgb(6, 6, 7);">分段堆的构建与管理</font>**
+ **<font style="color:rgb(6, 6, 7);">分块策略</font>**<font style="color:rgb(6, 6, 7);">：将候选点分成多个块，每个块的大小为</font>`ef`<font style="color:rgb(6, 6, 7);">，块的数量为</font>`k/ef`<font style="color:rgb(6, 6, 7);">。</font>
+ **<font style="color:rgb(6, 6, 7);">堆的构建</font>**<font style="color:rgb(6, 6, 7);">：在候选点数量达到</font>`k`<font style="color:rgb(6, 6, 7);">时，对每个块分别构建堆，并记录每个块的最大值</font><font style="color:rgb(6, 6, 7);">。</font>
+ **<font style="color:rgb(6, 6, 7);">全局管理</font>**<font style="color:rgb(6, 6, 7);">：维护一个全局的最小堆</font>`key`<font style="color:rgb(6, 6, 7);">，存储每个块的最大值及其对应的块起始位置</font><font style="color:rgb(6, 6, 7);">。通过</font>`key`<font style="color:rgb(6, 6, 7);">堆可以快速找到当前所有块中的最大值，从而确定全局的下界</font>`lowerBound`<font style="color:rgb(6, 6, 7);">。</font>
+ **<font style="color:rgb(6, 6, 7);">延迟建堆</font>**<font style="color:rgb(6, 6, 7);">：同时，可以发现的是，当结果节点不足时，完全可以不需要构建堆，而尽管将结果放入。只有当超过ef个时，才会进行换入换出的堆操作，所以可以在建堆上使用异步建堆（每有一个小堆慢，建堆），或者延迟建堆（到达ef个时才建堆），如此可以获得少许性能提升。</font>

#### <font style="color:rgb(6, 6, 7);">3.</font><font style="color:rgb(6, 6, 7);"> </font>**<font style="color:rgb(6, 6, 7);">堆操作的优化</font>**
+ **<font style="color:rgb(6, 6, 7);">插入操作</font>**<font style="color:rgb(6, 6, 7);">：当新点的相似度小于</font>`lowerBound`<font style="color:rgb(6, 6, 7);">时，需要将其插入到对应的块中。通过</font>`key`<font style="color:rgb(6, 6, 7);">堆快速定位到需要更新的块，并对该块的堆进行调整</font><font style="color:rgb(6, 6, 7);">。</font>
+ **<font style="color:rgb(6, 6, 7);">更新操作</font>**<font style="color:rgb(6, 6, 7);">：在更新块的堆时，利用分段堆的局部性，减少内存访问的范围，从而提高缓存性能</font><font style="color:rgb(6, 6, 7);">。</font>
+ **<font style="color:rgb(6, 6, 7);">预取优化</font>**<font style="color:rgb(6, 6, 7);">：通过预取指令（如</font>`_mm_prefetch`<font style="color:rgb(6, 6, 7);">），提前加载可能访问的内存数据，减少内存延迟</font><font style="color:rgb(6, 6, 7);">。</font>

#### <font style="color:rgb(6, 6, 7);">4.</font><font style="color:rgb(6, 6, 7);"> </font>**<font style="color:rgb(6, 6, 7);">性能提升的局限性</font>**
<font style="color:rgb(6, 6, 7);">尽管分段堆在理论上可以提高缓存性能，但实际测试中性能提升仅为5%</font><font style="color:rgb(6, 6, 7);">。这可能是因为：</font>

+ **<font style="color:rgb(6, 6, 7);">缓存行大小限制</font>**<font style="color:rgb(6, 6, 7);">：即使使用分段堆，每个堆的大小仍然可能超过CPU缓存行（64字节）的大小，导致缓存失效。</font>
+ **<font style="color:rgb(6, 6, 7);">多线程开销</font>**<font style="color:rgb(6, 6, 7);">：在多线程环境下，分段堆的管理可能会增加线程同步的开销，抵消部分性能提升</font><font style="color:rgb(6, 6, 7);">。</font>
+ **<font style="color:rgb(6, 6, 7);">数据局部性不足</font>**<font style="color:rgb(6, 6, 7);">：如果数据本身在内存中分布不够局部，即使使用分段堆，也难以充分利用缓存</font><font style="color:rgb(6, 6, 7);">。</font>

#### <font style="color:rgb(6, 6, 7);">5.</font><font style="color:rgb(6, 6, 7);"> </font>**<font style="color:rgb(6, 6, 7);">进一步优化方向</font>**
+ **<font style="color:rgb(6, 6, 7);">数据压缩</font>**<font style="color:rgb(6, 6, 7);">：可以考虑使用数据压缩技术（如SQ4）减少内存占用，从而进一步提高缓存利用率</font><font style="color:rgb(6, 6, 7);">。</font>
+ **<font style="color:rgb(6, 6, 7);">并行化优化</font>**<font style="color:rgb(6, 6, 7);">：在构建分段堆时，可以尝试并行化操作，减少构建时间</font><font style="color:rgb(6, 6, 7);">。</font>
+ **<font style="color:rgb(6, 6, 7);">硬件特性利用</font>**<font style="color:rgb(6, 6, 7);">：结合现代CPU的特性（如AVX指令集）进一步优化内存访问和计算。</font>

<font style="color:rgb(6, 6, 7);">通过引入分段堆，VSAG的HNSW实现尝试在缓存性能上进行优化，但实际效果有限。未来可以通过结合数据压缩、并行化和硬件特性进一步提升性能</font>

```cpp
+-------------------+-------------------+-------------------+ ... +-------------------+
|      堆1          |      堆2          |      堆3          | ... |      堆10         |
+-------------------+-------------------+-------------------+ ... +-------------------+
| [最小堆结构]      | [最小堆结构]      | [最小堆结构]      | ... | [最小堆结构]      |
+-------------------+-------------------+-------------------+ ... +-------------------+
        |                   |                   |               ...           |
        |                   |                   |               ...           |
        v                   v                   v               ...           v
+-------------------+-------------------+-------------------+ ... +-------------------+
| 堆1的最大值       | 堆2的最大值       | 堆3的最大值       | ... | 堆10的最大值      |
+-------------------+-------------------+-------------------+ ... +-------------------+

            ↓
        +-------------------+
        |     key堆         |
        | [堆1最大值]       |
        | [堆2最大值]       |
        | [堆3最大值]       |
        | ...               |
        +-------------------+

```

最终实现的代码：

```cpp
template <bool has_deletions, bool collect_metrics = false>
std::vector<std::pair<float, int64_t>>
searchBaseLayerSTLarge(tableint ep_id,
const void* data_point,
size_t k,
size_t ef,
BaseFilterFunctor* isIdAllowed = nullptr) const {
    auto vl = visited_list_pool_->getFreeVisitedList();
    vl_type* visited_array = vl->mass;
    vl_type visited_array_tag = vl->curV;
    auto comp = CompareByFirst();
    // 声明每个块大小为常量 每个区间ef/100的长度
    const size_t block_size = ef;
    //声明有多少块 10000/100=100个区间
    const size_t block_nums = k / ef;
    // 存储候选值的数组，分成block_nums个块，每个块是一个堆
    alignas(64) std::vector<std::pair<float, int64_t>> vectors;
    vectors.reserve(k);

    // 存储每个块的最大值及其在data中的索引
    alignas(64) std::vector<std::pair<float, int64_t>> key;
    key.reserve(block_nums);

    std::priority_queue<std::pair<float, int64_t>,
    vsag::Vector<std::pair<float, int64_t>>,
    CompareByFirst>
    candidate_set(allocator_);

    float lowerBound;
    float dist = fstdistfunc_(data_point, getDataByInternalId(ep_id), dist_func_param_);
    lowerBound = dist;

    // 初始点加入vectors
    vectors.emplace_back(dist, ep_id);
    visited_array[ep_id] = visited_array_tag;
    candidate_set.emplace(-dist, ep_id);

    while (!candidate_set.empty()) {
        std::pair<float, tableint> current_node_pair = candidate_set.top();

        if ((-current_node_pair.first) > lowerBound && vectors.size() >= k) {
            break;
        }
        candidate_set.pop();

        tableint current_node_id = current_node_pair.second;
        int* data_ptr = (int*)get_linklist0(current_node_id);
        size_t size = getListCount((linklistsizeint*)data_ptr);

        // 预取优化保持不变
        auto vector_data_ptr =
        data_level0_memory_->GetElementPtr((*(data_ptr + 1)), offsetData_);
        #ifdef USE_SSE
        _mm_prefetch((char*)(visited_array + *(data_ptr + 1)), _MM_HINT_T0);
        _mm_prefetch((char*)(visited_array + *(data_ptr + 1) + 64), _MM_HINT_T0);
        _mm_prefetch(vector_data_ptr, _MM_HINT_T0);
        _mm_prefetch((char*)(data_ptr + 2), _MM_HINT_T0);
        #endif

        for (size_t j = 1; j <= size; j++) {
            tableint candidate_id = *(data_ptr + j);
            size_t pre_l = std::min(j, size - 2);
            auto vector_data_ptr =
            data_level0_memory_->GetElementPtr((*(data_ptr + pre_l + 1)), offsetData_);
            #ifdef USE_SSE
            _mm_prefetch((char*)(visited_array + *(data_ptr + pre_l + 1)), _MM_HINT_T0);
            _mm_prefetch(vector_data_ptr, _MM_HINT_T0);  ////////////
            #endif
            if (visited_array[candidate_id] != visited_array_tag) {
                visited_array[candidate_id] = visited_array_tag;

                char* currObj1 = (getDataByInternalId(candidate_id));
                float dist = fstdistfunc_(data_point, currObj1, dist_func_param_);

                if (vectors.size() < k) {
                    // data还未满，直接添加
                    vectors.emplace_back(dist, candidate_id);
                    candidate_set.emplace(-dist, candidate_id);
                    auto vector_data_ptr = data_level0_memory_->GetElementPtr(
                    candidate_set.top().second, offsetLevel0_);
                    #ifdef USE_SSE
                    _mm_prefetch(vector_data_ptr, _MM_HINT_T0);
                    #endif
                    // 当data达到k大小时，建立分块堆结构
                    if (vectors.size() == k) {
                        // 为每个块建堆 多线程时间会翻倍？？为什么？？不知道cmakelist怎么弄的，虽然进程线程使用上去了，但是里面打印还是单线程。
                        // #pragma omp parallel for
                        for (size_t i = 0; i < block_nums; i++) {
                            size_t start = i * block_size;
                            size_t end = (i + 1) * block_size;
                            std::make_heap(
                                vectors.begin() + start, vectors.begin() + end, comp);

                            // 记录每个块的最大值到key中
                            float max_value = (vectors.begin() + start)->first;
                            key.emplace_back(max_value, start);
                        }
                        // 建立key的最小堆
                        std::make_heap(key.begin(), key.end(), comp);
                        lowerBound = key.front().first;
                    }
                } else if (dist < lowerBound) {
                    candidate_set.emplace(-dist, candidate_id);
                    auto vector_data_ptr = data_level0_memory_->GetElementPtr(
                    candidate_set.top().second, offsetLevel0_);
                    #ifdef USE_SSE
                    _mm_prefetch(vector_data_ptr, _MM_HINT_T0);
                    #endif
                    // 找到key中最大值所在的块
                    std::pop_heap(key.begin(), key.end());
                    size_t block_start = key.back().second;

                    // 更新对应块中的最大值
                    auto block_begin = vectors.begin() + block_start;
                    auto block_end = block_begin + block_size;
                    #ifdef USE_SSE
                    _mm_prefetch(reinterpret_cast<const char*>(&vectors[block_start]),
                        _MM_HINT_T0);
                    _mm_prefetch(reinterpret_cast<const char*>(&vectors[block_start + 4]),
                        _MM_HINT_T0);
                    #endif
                    std::pop_heap(block_begin, block_end, comp);

                    *(block_end - 1) = std::make_pair(dist, candidate_id);

                    std::push_heap(block_begin, block_end, comp);

                    // 更新key
                    key.back() = std::make_pair(block_begin->first, block_start);
                    std::push_heap(key.begin(), key.end(), comp);
                    lowerBound = key.front().first;
                }
            }
        }
    }

    visited_list_pool_->releaseVisitedList(vl);
    // auto c = CompareByFirstReverse();
    // sort(vectors.rbegin(), vectors.rend(), comp);
    // #pragma omp parallel
    //         { quick_sort_parallel(vectors, 0, vectors.size() - 1, c); }
    return std::move(vectors);
}

```

分段堆实测下来只有很小的性能提升（5%）。也没有用上sq4，具体效果还是要进行测试。

